{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Konst-Andre25/-VK-/blob/main/Copy_of_BestStudyModelRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray=='2.2.0'\n",
        "!pip install torch =='2.1.0+cu121'\n",
        "!pip install torchvision=='0.16.0+cu121'\n",
        "!pip install -U tensorboardx\n",
        "!pip install \"pydantic<2\"\n",
        "!pip install --upgrade google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUeDoO3AqpsI",
        "outputId": "4caa8d08-f7e4-4a78-d6f2-1ba35cf60ea1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray==2.2.0\n",
            "  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (23.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (3.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (2.31.0)\n",
            "Collecting virtualenv>=20.0.24 (from ray==2.2.0)\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (1.62.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (23.2)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.2.0) (1.25.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.24->ray==2.2.0)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray==2.2.0) (4.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.2.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.2.0) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.2.0) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.2.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.2.0) (2024.2.2)\n",
            "Installing collected packages: distlib, virtualenv, ray\n",
            "Successfully installed distlib-0.3.8 ray-2.2.0 virtualenv-20.25.1\n",
            "\u001b[31mERROR: Invalid requirement: '==2.1.0+cu121'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torchvision==0.16.0+cu121 in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.0+cu121) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision==0.16.0+cu121) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.0+cu121) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision==0.16.0+cu121) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision==0.16.0+cu121) (1.3.0)\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n",
            "Installing collected packages: tensorboardx\n",
            "Successfully installed tensorboardx-2.6.2.2\n",
            "Collecting pydantic<2\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2) (4.10.0)\n",
            "Installing collected packages: pydantic\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.3\n",
            "    Uninstalling pydantic-2.6.3:\n",
            "      Successfully uninstalled pydantic-2.6.3\n",
            "Successfully installed pydantic-1.10.14\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.122.0-py2.py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.62.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.2.2)\n",
            "Installing collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "Successfully installed google-api-python-client-2.122.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pZ7FkdPFqYJH"
      },
      "outputs": [],
      "source": [
        "\n",
        "from functools import partial\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from ray import tune\n",
        "from ray.air import Checkpoint, session\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "\n",
        "import torch.utils.data as data\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.http import MediaIoBaseDownload,MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "import pprint as pp\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Настройка работы с Google Drive'''\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
        "SERVICE_ACCOUNT_FILE = 'cryps-414010-041e36d94a74.json'\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "results = service.files().list(pageSize=10,\n",
        "                               fields=\"nextPageToken, files(id, name, mimeType)\").execute()"
      ],
      "metadata": {
        "id": "Q3iV91Mn0NXw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3vVRRS9eqYJL"
      },
      "outputs": [],
      "source": [
        "'''Разделим датасет на тестовую и обучающую выборки'''\n",
        "def DataPreprocess(df, train_percent):\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    '''Преобразуем Dataset к типу float32 и выделим timeseries и таргет данные'''\n",
        "    df = df.iloc[:, :].values.astype('float32')\n",
        "    timeseries = df\n",
        "    target = df[:, 0]\n",
        "\n",
        "    '''Нормализуем данные для обчуения'''\n",
        "    timeseries = scaler.fit_transform(timeseries)\n",
        "\n",
        "    '''Разделим данные на train и тест'''\n",
        "    train_size = int(len(df)*train_percent)\n",
        "    X_train, X_test = timeseries[:train_size], timeseries[train_size:]\n",
        "    y_train, y_test = target[:train_size], target[train_size:]\n",
        "\n",
        "    return torch.tensor(X_train), torch.tensor(y_train), torch.tensor(X_test), torch.tensor(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NQttK_C1qYJM"
      },
      "outputs": [],
      "source": [
        "'''Данная функция преобразует датасет с учётом скользящего окна для работы в формате временных рядов'''\n",
        "def SlidingWindow(X, y, window):\n",
        "    X_window, y_window = torch.ones(len(y) - window, window, X.shape[1]) * np.nan, torch.ones(len(y) - window, window) * np.nan\n",
        "    for i in range(len(X)- window):\n",
        "        X_window[i] = X[i:i+window, :]\n",
        "        y_window[i] = y[i+1:i+window+1]\n",
        "    return X_window, y_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "otioBf14qYJN"
      },
      "outputs": [],
      "source": [
        "'''Модель нейронной сети на базе LSTM ячейки'''\n",
        "class NN_LSTM(nn.Module):\n",
        "    def __init__(self, metric_count=1, hidden_size=500, dropout = 0.5, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=metric_count, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p = dropout)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S5KTboncqYJO"
      },
      "outputs": [],
      "source": [
        "'''Модель нейронной сети на базе GRU ячейки'''\n",
        "class NN_GRU(nn.Module):\n",
        "    def __init__(self, metric_count=1, hidden_size=500, dropout = 0.5, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.GRU(input_size=metric_count, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p = dropout)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Модель нейронной сети на базе GRU ячейки'''\n",
        "class NN_RNN(nn.Module):\n",
        "    def __init__(self, metric_count=1, hidden_size=500, dropout = 0.5, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.RNN(input_size=metric_count, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p = dropout)\n",
        "        self.linear = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "4ksP_6KgSqsN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hToIeXpGqYJP"
      },
      "outputs": [],
      "source": [
        "def load_data(window=3, train_percent=0.8, df=None):\n",
        "        train_size = int(len(df)*train_percent)\n",
        "        X_train, y_train, X_test, y_test = DataPreprocess(df = df, train_percent = train_percent)\n",
        "        X_train, y_train = SlidingWindow(X_train, y_train, window)\n",
        "        X_test, y_test = SlidingWindow(X_test, y_test, window)\n",
        "\n",
        "        return (X_train.cuda(), y_train.cuda(), X_test.cuda(), y_test.cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jZtp7ACQqYJP"
      },
      "outputs": [],
      "source": [
        "def train_cifar(config, df):\n",
        "    train_percent=config['train_percent']\n",
        "    metric_count=df.shape[1]\n",
        "    window=config['window']\n",
        "    num_epoch = config['epoch']\n",
        "\n",
        "    net = NN_RNN(metric_count=metric_count, hidden_size=config['hidden'], dropout=config['drop'], num_layers=config['n_layer'])\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.cuda()\n",
        "\n",
        "    checkpoint = session.get_checkpoint()\n",
        "\n",
        "    if checkpoint:\n",
        "        checkpoint_state = checkpoint.to_dict()\n",
        "        start_epoch = checkpoint_state[\"epoch\"]\n",
        "        net.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    X_train, y_train, X_test, y_test = load_data(window=window, train_percent=train_percent, df = df)\n",
        "    train_loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=int(config['batch_size']))\n",
        "    val_loader = data.DataLoader(data.TensorDataset(X_test, y_test), shuffle=True, batch_size=int(config['batch_size']))\n",
        "\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    for epoch in range(start_epoch, num_epoch):\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        size = len(train_loader.dataset)\n",
        "        for batch, (X_batch, y_batch) in enumerate(train_loader):\n",
        "\n",
        "            X_batch,y_batch = X_batch, y_batch\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred = net(X_batch).view(-1, window)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "            if batch % 500 == 0:  # print every 100 mini-batches\n",
        "                print(\n",
        "                    \"[%d, %5d] loss: %.3f\"\n",
        "                    % (epoch + 1, batch + 1, running_loss / epoch_steps)\n",
        "                )\n",
        "                running_loss = 0.0\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0.0\n",
        "    val_steps = 0\n",
        "\n",
        "    for batch, (X_test, y_test) in enumerate(val_loader):\n",
        "            with torch.no_grad():\n",
        "                y_pred = net(X_test).view(-1, window)\n",
        "                loss = criterion(y_pred, y_test).cpu()\n",
        "                rmse_loss = np.sqrt(loss)\n",
        "                val_loss += rmse_loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "\n",
        "    checkpoint_data = {\n",
        "            \"epoch\": epoch,\n",
        "            \"net_state_dict\": net.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "        }\n",
        "    checkpoint = Checkpoint.from_dict(checkpoint_data)\n",
        "\n",
        "    session.report(\n",
        "            {\"loss\": val_loss/val_steps},\n",
        "            checkpoint=checkpoint,\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rPZXPJ1lqYJQ"
      },
      "outputs": [],
      "source": [
        "def test_loss(model, window,train_percent, df, f):\n",
        "\n",
        "        X_train, y_train, X_test, Y_test = load_data(window=window, train_percent=0.1, df = df)\n",
        "        test_loader = data.DataLoader(data.TensorDataset(X_test, Y_test), shuffle=False, batch_size=1)\n",
        "        criter = nn.MSELoss()\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        R_out = 1\n",
        "        ret = [R_out]\n",
        "        trading_strategy = list()\n",
        "        FinalValue = 1\n",
        "        InitValue = 1\n",
        "\n",
        "        for _, (X_test, y_test) in enumerate(test_loader):\n",
        "            with torch.no_grad():\n",
        "                y_pred = model(X_test).view(-1, window)\n",
        "                loss = criter(y_pred, y_test).cpu()\n",
        "                rmse_loss = np.sqrt(loss)\n",
        "                val_loss += rmse_loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "                close = y_pred[-1,-1]\n",
        "                open = y_pred[-1,-2]\n",
        "                R_c = ((1-f)*close-(1+f)*open)/open\n",
        "                R_out = R_out*(1+R_c)\n",
        "                ret.append(R_out)\n",
        "                # trading_decision = trading_algo(R_c)\n",
        "                # trading_strategy.append(trading_decision)\n",
        "\n",
        "        ROI = (R_out-1)/1\n",
        "        return val_loss/val_steps,  ret, Y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JpT4fBa3qYJR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "T_A6p1rIqYJR"
      },
      "outputs": [],
      "source": [
        "def main( num_s = 50, max_num_epoch= 10):\n",
        "    # Выгрузка данных в датафрейм\n",
        "    metrics= ['PriceUSD', 'TxTfrValMedUSD', 'SplyExpFut10yr', 'TxTfrValMedNtv', 'VtyDayRet180d',\n",
        "    'VtyDayRet30d']\n",
        "    metric_count = len(metrics)\n",
        "    df = pd.read_csv(r'Data/ETH_PriceUSD.csv')[metrics].dropna()\n",
        "\n",
        "    config = {\n",
        "                \"window\": tune.choice(np.arange(1, 5)),\n",
        "                \"train_percent\": tune.loguniform(0.8, 0.85),\n",
        "                \"hidden\": tune.choice([2 ** i for i in range(8, 10)]),\n",
        "                \"drop\": tune.loguniform(1e-1, 3e-1),\n",
        "                \"lr\": tune.loguniform(1e-4, 1e-1),\n",
        "                \"n_layer\": tune.choice([1]),\n",
        "                \"batch_size\": tune.choice([2, 4, 8, 11, 16]),\n",
        "                \"epoch\":max_num_epoch\n",
        "                }\n",
        "\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epoch,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2,\n",
        "    )\n",
        "\n",
        "    result = tune.run(\n",
        "        partial(train_cifar, df=df),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
        "        config=config,\n",
        "        num_samples=num_s,\n",
        "        scheduler=scheduler,\n",
        "    )\n",
        "\n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(f\"Best trial config: {best_trial.config}\")\n",
        "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
        "\n",
        "\n",
        "    best_trained_model = NN_RNN(metric_count=metric_count, hidden_size=best_trial.config['hidden'], dropout=best_trial.config['drop'], num_layers=best_trial.config['n_layer'])\n",
        "\n",
        "    best_checkpoint = best_trial.checkpoint.to_air_checkpoint()\n",
        "    best_checkpoint_data = best_checkpoint.to_dict()\n",
        "    best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n",
        "\n",
        "    torch.save(best_trained_model.state_dict(), r\"Data/BestModels/BestModel.pt\")\n",
        "\n",
        "    with open(r'Data/BestModels/BestConfig.txt', \"w\") as f:\n",
        "        f.writelines(f\"{param} = {best_trial.config[param]}\\n\" for param in best_trial.config)\n",
        "\n",
        "    folder_id = '1Ksmrr0Q7f4Dstz_oE3XHu6_jeOx2BuEI'\n",
        "\n",
        "    model_filename = 'BestModel.pt'\n",
        "    config_filename = 'BestConfig.txt'\n",
        "\n",
        "    model_filepath = 'Data/BestModels/BestModel.pt'\n",
        "    file_metadata = {\n",
        "                    'name': model_filename,\n",
        "                    'parents': [folder_id]\n",
        "                }\n",
        "    media = MediaFileUpload(model_filepath, resumable=True)\n",
        "    r = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "    pp.pprint(r)\n",
        "\n",
        "    config_filepath = 'Data/BestModels/BestConfig.txt'\n",
        "    file_metadata = {\n",
        "                    'name': config_filename,\n",
        "                    'parents': [folder_id]\n",
        "                }\n",
        "    media = MediaFileUpload(config_filepath, resumable=True)\n",
        "    r = service.files().create(body=file_metadata, media_body=media, fields='id', ocrLanguage = 'en').execute()\n",
        "    pp.pprint(r)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "_41DiHLQqYJS",
        "outputId": "9ed0617b-0a9c-463c-c9f0-8ea75d743e66"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2024-03-13 05:35:48</td></tr>\n",
              "<tr><td>Running for: </td><td>00:00:19.46        </td></tr>\n",
              "<tr><td>Memory:      </td><td>2.5/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: -990.8318918062294<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.29 GiB heap, 0.0/3.65 GiB objects\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">    drop</th><th style=\"text-align: right;\">  hidden</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  n_layer</th><th style=\"text-align: right;\">  train_percent</th><th style=\"text-align: right;\">  window</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_cifar_80ab1_00000</td><td>TERMINATED</td><td>172.28.0.12:2120</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">0.17393 </td><td style=\"text-align: right;\">     512</td><td style=\"text-align: right;\">0.0497666  </td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0.804088</td><td style=\"text-align: right;\">       2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.0908 </td><td style=\"text-align: right;\"> 313.133</td></tr>\n",
              "<tr><td>train_cifar_80ab1_00001</td><td>TERMINATED</td><td>172.28.0.12:2253</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">0.136443</td><td style=\"text-align: right;\">     512</td><td style=\"text-align: right;\">0.000130583</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">       0.812681</td><td style=\"text-align: right;\">       3</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.08463</td><td style=\"text-align: right;\">1668.53 </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(func pid=2018)\u001b[0m [3,   501] loss: 127767.646\n",
            "\u001b[2m\u001b[36m(func pid=2120)\u001b[0m [1,     1] loss: 153339.922\n",
            "\u001b[2m\u001b[36m(func pid=2120)\u001b[0m [2,     1] loss: 45412.586\n",
            "\u001b[2m\u001b[36m(func pid=2120)\u001b[0m [3,     1] loss: 161748.531\n",
            "\u001b[2m\u001b[36m(func pid=2120)\u001b[0m [4,     1] loss: 10958.486\n",
            "\u001b[2m\u001b[36m(func pid=2120)\u001b[0m [5,     1] loss: 78899.805\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_cifar_80ab1_00000</td><td>2024-03-13_05-35-39</td><td>True  </td><td>                </td><td>d387958309684ab6a7e41397597e29ca</td><td>738eac4684f5</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\"> 313.133</td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2120</td><td>True               </td><td style=\"text-align: right;\">             5.0908 </td><td style=\"text-align: right;\">           5.0908 </td><td style=\"text-align: right;\">       5.0908 </td><td style=\"text-align: right;\"> 1710308139</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>80ab1_00000</td><td style=\"text-align: right;\">    0.0117235</td></tr>\n",
              "<tr><td>train_cifar_80ab1_00001</td><td>2024-03-13_05-35-48</td><td>True  </td><td>                </td><td>5ae37086476f4a2da58c201f8552b9f0</td><td>738eac4684f5</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1668.53 </td><td>172.28.0.12</td><td style=\"text-align: right;\"> 2253</td><td>True               </td><td style=\"text-align: right;\">             5.08463</td><td style=\"text-align: right;\">           5.08463</td><td style=\"text-align: right;\">       5.08463</td><td style=\"text-align: right;\"> 1710308148</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>80ab1_00001</td><td style=\"text-align: right;\">    0.0034318</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(func pid=2253)\u001b[0m [1,     1] loss: 2401125.500\n",
            "\u001b[2m\u001b[36m(func pid=2253)\u001b[0m [2,     1] loss: 3109616.000\n",
            "\u001b[2m\u001b[36m(func pid=2253)\u001b[0m [3,     1] loss: 2007300.375\n",
            "\u001b[2m\u001b[36m(func pid=2253)\u001b[0m [4,     1] loss: 579350.875\n",
            "\u001b[2m\u001b[36m(func pid=2253)\u001b[0m [5,     1] loss: 767461.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-03-13 05:35:49,092\tINFO tune.py:762 -- Total run time: 19.60 seconds (19.45 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial config: {'window': 2, 'train_percent': 0.8040883544510221, 'hidden': 512, 'drop': 0.17393007885348166, 'lr': 0.04976662892030535, 'n_layer': 1, 'batch_size': 8, 'epoch': 5}\n",
            "Best trial final validation loss: 313.1325689951579\n",
            "{'id': '1YADMieSSkx0qx1B7mq1rK672UFDkJubx'}\n",
            "{'id': '1NGGLYPuNoNjjMrVLCp_T6wp4uoexY2g-'}\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main(num_s=2, max_num_epoch=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1QgAfNSUy0PZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}